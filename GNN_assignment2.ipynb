{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNz8dZhguUsy77XnutjK0fI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkar243/AWS_Config/blob/master/GNN_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3O_zshpG9jE",
        "outputId": "a64e5aeb-d682-4df0-d8d8-3723553e6772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (71.0.4)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: littleutils, outdated, torch-geometric, ogb\n",
            "Successfully installed littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2 torch-geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch-geometric ogb scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from ogb.linkproppred import LinkPropPredDataset, Evaluator\n"
      ],
      "metadata": {
        "id": "p1eAZBxcHOMr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Define GCN Model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7oZEfkOwHYGT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: Load the Dataset\n",
        "dataset = LinkPropPredDataset(name=\"ogbl-collab\")\n",
        "data = dataset[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHNlhhphHeUL",
        "outputId": "355f0829-3f0d-494a-ec2e-760a6ab965ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/linkproppred/collab.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.11 GB: 100%|██████████| 117/117 [00:06<00:00, 17.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/collab.zip\n",
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 29.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 5: Move Data to the Device\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Convert numpy arrays to torch tensors and move them to the device\n",
        "edge_index = torch.tensor(data['edge_index'], dtype=torch.long).to(device)\n",
        "node_feat = torch.tensor(data['node_feat'], dtype=torch.float).to(device)  # Node features\n",
        "\n"
      ],
      "metadata": {
        "id": "fz_eeolqHmTa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step6: Initialize the model and optimizer\n",
        "model = GCN(in_channels=node_feat.size(1), hidden_channels=64, out_channels=64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "cZbxaFmJIl-H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate Negative Samples\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "# Sample negative edges\n",
        "num_nodes = node_feat.size(0)\n",
        "neg_edge_index = negative_sampling(edge_index, num_nodes=num_nodes)\n"
      ],
      "metadata": {
        "id": "3Rl34cbqJ_Gn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Labels\n",
        "import torch\n",
        "\n",
        "# Create labels for positive and negative samples\n",
        "num_pos_edges = edge_index.size(1)\n",
        "num_neg_edges = neg_edge_index.size(1)\n",
        "\n",
        "# True edges labeled as 1\n",
        "pos_labels = torch.ones(num_pos_edges)\n",
        "\n",
        "# False edges labeled as 0\n",
        "neg_labels = torch.zeros(num_neg_edges)\n",
        "\n",
        "# Concatenate both positive and negative labels\n",
        "labels = torch.cat([pos_labels, neg_labels], dim=0).to(device)\n"
      ],
      "metadata": {
        "id": "I7TIJVtsKEva"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute score and loss\n",
        "# Forward pass\n",
        "out = model(node_feat, edge_index)\n",
        "\n",
        "# Get node embeddings for positive and negative edges\n",
        "pos_out = out[edge_index[0]]  # Source node embeddings for positive edges\n",
        "pos_out = torch.sum(pos_out * out[edge_index[1]], dim=1)  # Dot product for edge scores\n",
        "\n",
        "neg_out = out[neg_edge_index[0]]  # Source node embeddings for negative edges\n",
        "neg_out = torch.sum(neg_out * out[neg_edge_index[1]], dim=1)  # Dot product for edge scores\n",
        "\n",
        "# Concatenate positive and negative edge scores\n",
        "edge_scores = torch.cat([pos_out, neg_out], dim=0)\n",
        "\n",
        "# Compute loss\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "loss = criterion(edge_scores, labels)\n"
      ],
      "metadata": {
        "id": "aN_4qpk1KJLP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete Training Loop\n",
        "import torch\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Prepare data\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "edge_index = torch.tensor(data['edge_index'], dtype=torch.long).to(device)\n",
        "node_feat = torch.tensor(data['node_feat'], dtype=torch.float).to(device)\n",
        "\n",
        "# Generate negative samples\n",
        "num_nodes = node_feat.size(0)\n",
        "neg_edge_index = negative_sampling(edge_index, num_nodes=num_nodes)\n",
        "\n",
        "# Create labels\n",
        "num_pos_edges = edge_index.size(1)\n",
        "num_neg_edges = neg_edge_index.size(1)\n",
        "pos_labels = torch.ones(num_pos_edges).to(device)\n",
        "neg_labels = torch.zeros(num_neg_edges).to(device)\n",
        "labels = torch.cat([pos_labels, neg_labels], dim=0).to(device)\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "model = GCN(in_channels=node_feat.size(1), hidden_channels=64, out_channels=64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    out = model(node_feat, edge_index)\n",
        "\n",
        "    # Get node embeddings for positive and negative edges\n",
        "    pos_out = out[edge_index[0]]\n",
        "    pos_out = torch.sum(pos_out * out[edge_index[1]], dim=1)\n",
        "\n",
        "    neg_out = out[neg_edge_index[0]]\n",
        "    neg_out = torch.sum(neg_out * out[neg_edge_index[1]], dim=1)\n",
        "\n",
        "    # Concatenate positive and negative edge scores\n",
        "    edge_scores = torch.cat([pos_out, neg_out], dim=0)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(edge_scores, labels)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss every few epochs\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation (optional)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(node_feat, edge_index)\n",
        "\n",
        "    # Get embeddings for positive and negative edges\n",
        "    pos_out = out[edge_index[0]]\n",
        "    pos_out = torch.sum(pos_out * out[edge_index[1]], dim=1)\n",
        "\n",
        "    neg_out = out[neg_edge_index[0]]\n",
        "    neg_out = torch.sum(neg_out * out[neg_edge_index[1]], dim=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    edge_scores = torch.cat([pos_out, neg_out], dim=0)\n",
        "    predictions = torch.sigmoid(edge_scores).cpu().numpy()\n",
        "    auc = roc_auc_score(labels.cpu().numpy(), predictions)\n",
        "    print(f'AUC Score: {auc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTgEYT7XKRw9",
        "outputId": "d2d266f9-3962-4698-beaf-6030be0aa6eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7771801948547363\n",
            "Epoch 2, Loss: 0.7187182903289795\n",
            "Epoch 4, Loss: 0.6417094469070435\n",
            "Epoch 6, Loss: 0.6535205245018005\n",
            "Epoch 8, Loss: 0.636506199836731\n",
            "Epoch 10, Loss: 0.6362978219985962\n",
            "Epoch 12, Loss: 0.6177603602409363\n",
            "Epoch 14, Loss: 0.601878821849823\n",
            "Epoch 16, Loss: 0.5889580249786377\n",
            "Epoch 18, Loss: 0.5724357962608337\n",
            "Epoch 20, Loss: 0.5567289590835571\n",
            "Epoch 22, Loss: 0.5433588027954102\n",
            "Epoch 24, Loss: 0.5348495244979858\n",
            "Epoch 26, Loss: 0.5260825157165527\n",
            "Epoch 28, Loss: 0.5170064568519592\n",
            "Epoch 30, Loss: 0.5099192261695862\n",
            "Epoch 32, Loss: 0.5044182538986206\n",
            "Epoch 34, Loss: 0.5002217888832092\n",
            "Epoch 36, Loss: 0.49593910574913025\n",
            "Epoch 38, Loss: 0.4918031096458435\n",
            "Epoch 40, Loss: 0.4874316453933716\n",
            "Epoch 42, Loss: 0.483011931180954\n",
            "Epoch 44, Loss: 0.47899842262268066\n",
            "Epoch 46, Loss: 0.4751671254634857\n",
            "Epoch 48, Loss: 0.4719536304473877\n",
            "Epoch 50, Loss: 0.46967098116874695\n",
            "Epoch 52, Loss: 0.46855732798576355\n",
            "Epoch 54, Loss: 0.4682421386241913\n",
            "Epoch 56, Loss: 0.468051552772522\n",
            "Epoch 58, Loss: 0.467517226934433\n",
            "Epoch 60, Loss: 0.46663278341293335\n",
            "Epoch 62, Loss: 0.46560633182525635\n",
            "Epoch 64, Loss: 0.4647063910961151\n",
            "Epoch 66, Loss: 0.46406763792037964\n",
            "Epoch 68, Loss: 0.4636135697364807\n",
            "Epoch 70, Loss: 0.4632680118083954\n",
            "Epoch 72, Loss: 0.4629790484905243\n",
            "Epoch 74, Loss: 0.46267765760421753\n",
            "Epoch 76, Loss: 0.4623437821865082\n",
            "Epoch 78, Loss: 0.46194279193878174\n",
            "Epoch 80, Loss: 0.4615134000778198\n",
            "Epoch 82, Loss: 0.4611344635486603\n",
            "Epoch 84, Loss: 0.4608241319656372\n",
            "Epoch 86, Loss: 0.46055087447166443\n",
            "Epoch 88, Loss: 0.4602678716182709\n",
            "Epoch 90, Loss: 0.45994940400123596\n",
            "Epoch 92, Loss: 0.45958560705184937\n",
            "Epoch 94, Loss: 0.45920196175575256\n",
            "Epoch 96, Loss: 0.45881086587905884\n",
            "Epoch 98, Loss: 0.45841488242149353\n",
            "AUC Score: 0.9562325541018166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming split_edge is already defined\n",
        "val_edges = torch.tensor(split_edge['valid']['edge'], dtype=torch.long).to(device)\n",
        "val_neg_edges = torch.tensor(split_edge['valid']['edge_neg'], dtype=torch.long).to(device)\n",
        "\n",
        "# Forward pass with validation edges\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(node_feat, edge_index)\n",
        "\n",
        "    # Get embeddings for positive and negative validation edges\n",
        "    pos_val_out = out[val_edges[:, 0]] * out[val_edges[:, 1]]\n",
        "    pos_val_out = torch.sum(pos_val_out, dim=1)\n",
        "\n",
        "    neg_val_out = out[val_neg_edges[:, 0]] * out[val_neg_edges[:, 1]]\n",
        "    neg_val_out = torch.sum(neg_val_out, dim=1)\n",
        "\n",
        "    # Combine and calculate the AUC\n",
        "    val_scores = torch.cat([pos_val_out, neg_val_out], dim=0)\n",
        "    val_labels = torch.cat([torch.ones(pos_val_out.size(0)), torch.zeros(neg_val_out.size(0))], dim=0).to(device)\n",
        "\n",
        "    val_predictions = torch.sigmoid(val_scores).cpu().numpy()\n",
        "    auc = roc_auc_score(val_labels.cpu().numpy(), val_predictions)\n",
        "    print(f'Validation AUC: {auc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulj-_-DTSiFW",
        "outputId": "6b605ba0-ce3f-47a2-eb5c-e5e3a3c3970c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.9236754544471073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming split_edge is already defined\n",
        "val_edges = torch.tensor(split_edge['valid']['edge'], dtype=torch.long).to(device)\n",
        "val_neg_edges = torch.tensor(split_edge['valid']['edge_neg'], dtype=torch.long).to(device)\n",
        "\n",
        "# Forward pass with validation edges\n",
        "model.eval()\n",
        "# Use the validation or test set for evaluation\n",
        "split_edge = dataset.get_edge_split()\n",
        "val_edges = split_edge['valid']['edge'].to(device)\n",
        "val_neg_edges = split_edge['valid']['edge_neg'].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Predict the scores for positive and negative edges\n",
        "    pos_scores = torch.sigmoid(model(node_feat, val_edges.t()))\n",
        "    neg_scores = torch.sigmoid(model(node_feat, val_neg_edges.t()))\n",
        "\n",
        "    # Compute the Hits@K metric using the Evaluator class\n",
        "    evaluator = Evaluator(name='ogbl-collab')\n",
        "    results = evaluator.eval({\n",
        "        'y_pred_pos': pos_scores,\n",
        "        'y_pred_neg': neg_scores,\n",
        "    })\n",
        "\n",
        "    print(f\"Hits@50: {results['hits@50']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "IrnZzwrfTGd4",
        "outputId": "461e7e26-8178-42aa-f67d-f29598bda200"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ogb/linkproppred/dataset.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train = torch.load(osp.join(path, 'train.pt'))\n",
            "/usr/local/lib/python3.10/dist-packages/ogb/linkproppred/dataset.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  valid = torch.load(osp.join(path, 'valid.pt'))\n",
            "/usr/local/lib/python3.10/dist-packages/ogb/linkproppred/dataset.py:140: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test = torch.load(osp.join(path, 'test.pt'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ab88d4782cbb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use the validation or test set for evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msplit_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_edge_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mval_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_edge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mval_neg_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_edge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edge_neg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
          ]
        }
      ]
    }
  ]
}